{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1975a096",
   "metadata": {},
   "source": [
    "> # Summarize Nike Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d46c7",
   "metadata": {},
   "source": [
    "In this notebook, our objective is to import customer reviews obtained through web scraping and subsequently generate a comprehensive CSV report summarizing pertinent information pertaining to the specified Nike product.\n",
    "\n",
    "To achieve this, we will create a function named `summarize()` with the following functionalities:\n",
    "\n",
    "1. Accept as a parameter the path to a csv file created by the first Notebook\n",
    "\n",
    "\n",
    "2. Create a 1-page pdf file that includes a summary of all the reviews in the csv.\n",
    "\n",
    "\n",
    "3. The nature of the summary is entirely free\n",
    "    - It can be text-based, visual-based, or a combination of both\n",
    "    - We should define what is important enough to be included in the summary.\n",
    "    - We will focus on creating a summary that would be the most informative for customers.\n",
    "    - The creation of the pdf should be done through the notebook with the use of every Python-based library we want. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0b799",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8192c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from functions.summary_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72010428",
   "metadata": {},
   "source": [
    "**Create Function to summarize the reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a46a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(path_csv_file):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    A query  containing the path of the CSV file containing the reviews\n",
    "\n",
    "    Function: \n",
    "    Importing the csv file from the current path, analyzing the reviews and create a Summary\n",
    "    \n",
    "    Output:\n",
    "    A PDF file, containg a Summary of product's reviews\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #import csv\n",
    "    reviews_eng = pd.read_csv(path_csv_file)\n",
    "    \n",
    "    \"\"\"\n",
    "    1. At first, we make a correction of dates, due to greek-text in months\n",
    "    \"\"\"\n",
    "    print('1. At first, we make a correction of dates, due to greek-text in months')\n",
    "    \n",
    "    #correction of dates\n",
    "    reviews_eng = date_correction(reviews_eng)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    2. Next, we will do a text analysis in order to find the frequencies of each word of all the reviews\n",
    "    \"\"\"\n",
    "    print('2. Next, we will do a text analysis in order to find the frequencies of each word of all the reviews')\n",
    "    \n",
    "    #define \n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    \n",
    "    #find frequencies\n",
    "    freq = find_freq(reviews_eng)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    3. After, we are going to do Aspect Mining of all the reviews using the Network Analysis method\n",
    "\n",
    "    \"\"\"\n",
    "    print('3. After, we are going to do Aspect Mining of all the reviews using the Network Analysis method')\n",
    "      \n",
    "    #Use network analysis to group and extract semantically similar aspects\n",
    "    aspects = get_aspects_from_undirected_graphs(freq,nx.algorithms.components.connected_components,0.8)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    4. Following, we will do Opinion Mining\n",
    "    \"\"\"\n",
    "    print('4. Following, we will do Opinion Mining')\n",
    "       \n",
    "    #extract opinons\n",
    "    opinions = get_opinions(reviews_eng.content, aspects)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    5. Next, we are going to find the positive and the negative aspects\n",
    "    \"\"\"\n",
    "    print('5. Next, we are going to find the positive and the negative aspects')\n",
    "    \n",
    "    #classify aspects into positives and negatives\n",
    "    positive_aspects, negative_aspects = classification_of_aspects(aspects,opinions)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    6. Following, we will classify the reviews into positive and negative based on rating\n",
    "    \"\"\"\n",
    "    print('6. Following, we will classify the reviews into positive and negative based on rating')\n",
    "    \n",
    "    #apply function for classification\n",
    "    reviews_eng['classif'] = reviews_eng['rating'].apply(classify)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    7. We will start the reporting process\n",
    "    \"\"\"\n",
    "    print('7. We will start the reporting process')\n",
    "        \n",
    "    #add year, month and month names into reviews df and create a yearly df\n",
    "    reviews_eng, reviews_eng_yearly = manipulate_df(reviews_eng)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    8. Plots\n",
    "    \"\"\"\n",
    "    print('8. Plots')\n",
    "    \n",
    "    \"\"\"\n",
    "    8.1. Wordcloud\n",
    "    \"\"\"\n",
    "    print('8.1. Wordcloud')\n",
    "    \n",
    "    #run function to create a wordcloud img    \n",
    "    _ = wordcloud(freq)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    8.2. Barplot-lineplot-> Basic graph with two y axis\n",
    "    \n",
    "    \"\"\"\n",
    "    print('8.2. Barplot-lineplot-> Basic graph with two y axis')\n",
    "    \n",
    "    #run function for basic chart\n",
    "    _ = basic_graph(reviews_eng_yearly)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    \"\"\"\n",
    "    9. Create the pdf including all the summaries regarding reviews\n",
    "    \"\"\"\n",
    "    print('9. Create the pdf including all the summaries regarding reviews') \n",
    "    \n",
    "    _ = create_and_export_pdf(reviews_eng,positive_aspects,negative_aspects)\n",
    "    \n",
    "    print('Done')\n",
    "    print(' ')\n",
    "    \n",
    "    return print(colored('Summary PDF has been successfully created and exported', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965b31f",
   "metadata": {},
   "source": [
    "**Import the reviews that we have previously downloaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a38ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mkarampasis\\\\Desktop\\\\Michalis\\\\master\\\\Review Summarization\\\\Review Summarization Karampasis\\\\nike airfoce 1 07 reviews.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the path where the notebook is located\n",
    "current_path = os.getcwd()\n",
    "\n",
    "#find the path where the csv file (reviews) is located\n",
    "path_csv_file = glob.glob(os.path.join(current_path, '*.csv'))[0]\n",
    "path_csv_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5de7e0",
   "metadata": {},
   "source": [
    "**Run function to summarize reviews and export a CSV report file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cc0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. At first, we make a correction of dates, due to greek-text in months\n",
      "Done\n",
      "2. Next, we will do a text analysis in order to find the frequencies of each word of all the reviews\n",
      "Done\n",
      "3. After, we are going to do Aspect Mining of all the reviews using the Network Analysis method\n",
      "Done\n",
      "4. Following, we will do Opinion Mining\n",
      "Done\n",
      "5. Next, we are going to find the positive and the negative aspects\n",
      "Done\n",
      "6. Following, we will classify the reviews into positive and negative based on rating\n",
      "Done\n",
      "7. We will start the reporting process\n",
      "Done\n",
      "8. Plots\n",
      "8.1. Wordcloud\n",
      "Done\n",
      "8.2. Barplot-lineplot-> Basic graph with two y axis\n",
      "Done\n",
      "9. Create the pdf including all the summaries regarding reviews\n",
      "Done\n",
      " \n",
      "\u001b[32mSummary PDF has been successfully created and exported\u001b[0m\n",
      "The total execution time was: 0:00:21.601488\n"
     ]
    }
   ],
   "source": [
    "#start time\n",
    "start = datetime.now()\n",
    "\n",
    "summarize(path_csv_file)\n",
    "\n",
    "#end time\n",
    "end = datetime.now()\n",
    "\n",
    "#total execution time\n",
    "execution_time = end-start\n",
    "print('The total execution time was:',execution_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
